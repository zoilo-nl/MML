{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_METADATA = \"musicnet_metadata.csv\"\n",
    "\n",
    "PATH_DATA = \"musicnet/data/\"\n",
    "PATH_LABELS = \"musicnet/labels/\"\n",
    "\n",
    "PATH_TRAIN_DATA = \"musicnet/train_data/\"\n",
    "PATH_TRAIN_LABELS = \"musicnet/train_labels/\"\n",
    "PATH_TEST_DATA = \"musicnet/test_data/\"\n",
    "PATH_TEST_LABELS = \"musicnet/test_labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_SR = 44100\n",
    "TARGET_SR = 16000\n",
    "FMIN = librosa.note_to_hz(\"A0\")\n",
    "FMIN_MIDI_INDEX = librosa.note_to_midi(\"A0\")\n",
    "N_NOTES = 88\n",
    "BINS_PER_NOTE = 1\n",
    "BINS_PER_OCTAVE = 12 * BINS_PER_NOTE\n",
    "N_BINS = N_NOTES * BINS_PER_NOTE\n",
    "\n",
    "WINDOW_LENGTH = 2048\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "frac_sr = TARGET_SR / ORIGINAL_SR\n",
    "sample_indexer = frac_sr / HOP_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "\n",
    "def data_to_midi(filename, data, bpm):\n",
    "\n",
    "    FRAME_DURATION = HOP_LENGTH/TARGET_SR # Frame duration in seconds\n",
    "    PPQN = (1/FRAME_DURATION)*16 # Pulses per quarter note\n",
    "    TEMPO = mido.bpm2tempo(bpm) # MIDI Tempo, microseconds per beat\n",
    "    \n",
    "    n_notes, n_frames = data.shape\n",
    "\n",
    "    # pad zeros so we can acknowledge inital and ending events\n",
    "    data = np.pad(data, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    mid = MidiFile()\n",
    "    \n",
    "    for i in range(n_notes):\n",
    "        note = i + FMIN_MIDI_INDEX # add the MIDI index\n",
    "        changes = np.nonzero(np.diff(data[i]))[0] # list with the index where the array changes from 0 to 1 or vice versa\n",
    "        if len(changes):\n",
    "            t = round(mido.second2tick(FRAME_DURATION*changes[0], PPQN, TEMPO))\n",
    "            track = MidiTrack()\n",
    "            track.append(Message('program_change', program=0, time=t)) # program 0 is Acoustic Grand Piano\n",
    "            for j in np.diff(changes):\n",
    "                t = round(mido.second2tick(FRAME_DURATION*j, PPQN, TEMPO))\n",
    "                track.append(Message('note_on', channel=0, note=note, velocity=64, time=t))\n",
    "                track.append(Message('note_off', channel=0, note=note, velocity=0, time=0))\n",
    "            \n",
    "            mid.tracks.append(track)\n",
    "    \n",
    "    mid.save(filename+'.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"1759\"\n",
    "data = np.load(filename+\"_prediction.npy\")\n",
    "\n",
    "bpm = 106 # Beats per minute\n",
    "data_to_midi(filename, data, bpm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
