{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                 # linear algebra\n",
    "import pandas as pd                # data processing\n",
    "import matplotlib.pyplot as plt    # basic plotting library\n",
    "import seaborn as sns              # more advanced visual plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "MAGIC gamma telescope data 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"fClass\"]\n",
    "df = pd.read_csv('magic04.data', names=headers)\n",
    "mapping = {'g': 1, 'h': 0}\n",
    "df[\"fClass\"] = df[\"fClass\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(data=df.corr(),annot=True,cmap=\"bone\",linewidths=1,fmt=\".2f\",linecolor=\"gray\")\n",
    "plt.title(\"Correlation Map\",fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()      # lightest and darkest cells are most correlated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df,\n",
    "             palette=\"husl\",\n",
    "             hue=\"fClass\",\n",
    "             vars=headers)\n",
    "plt.suptitle(\"PairPlot of Data Without Std. Dev. Fields\",fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[df['fAlpha'] == 0]))\n",
    "print(len(df[df['fAlpha'] == 90]))\n",
    "print(len(df[df['fSize'] == 0]))\n",
    "print(len(df[df['fLength'] == 0]))\n",
    "print(len(df[df['fWidth'] == 0]))\n",
    "df[df['fWidth'] < 1].hist(column='fWidth', bins=100)\n",
    "df[df['fWidth'] == 0].hist(column='fSize', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rescaled = pd.DataFrame()\n",
    "headers = [\"fLength\", \"fWidth\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fDist\",\"fAlpha\", \"fSize\",\"fClass\"]\n",
    "rescaled_headers = [ \"rescaled_length\", \"rescaled_width\",\"rescaled_conc\",\"rescaled_conc1\"  ,\"rescaled_asym\",\"rescaled_M3long\" ,\"rescaled_M3trans\",\"rescaled_dist\" ,\"alpha\",\"size\",\"rad\"]\n",
    "for i in range(0,8):\n",
    "    df_rescaled.insert(i, rescaled_headers[i] ,df[headers[i]]/df[\"fSize\"])\n",
    "df_rescaled.insert(8, \"alpha\" ,df[\"fAlpha\"])\n",
    "df_rescaled.insert(9, \"size\" ,df[\"fSize\"])\n",
    "df_rescaled.insert(10, \"rad\" ,df[\"fClass\"])\n",
    "# df_rescaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df.drop(df[df.fWidth == 0].index, inplace=True) # Drops rows where fWidth == 0\n",
    "\n",
    "Y = df[\"fClass\"].values\n",
    "# todrop = [\"fLength\", \"fWidth\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fDist\",\"fAlpha\", \"fSize\",\"fClass\"]\n",
    "# todrop = [ \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fDist\",\"fClass\"]\n",
    "# todrop = [ \"fClass\"]\n",
    "input_shape = (10,)\n",
    "to_abolish = [\"fClass\"]\n",
    "X = df.drop(to_abolish,axis=1).values\n",
    "\n",
    "# Y = df_rescaled[\"rad\"].values\n",
    "# X = df_rescaled.drop([\"rad\"],axis=1).values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Fischers linear discriminant\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# model = LinearDiscriminantAnalysis()\n",
    "# model.fit(X, Y)\n",
    "# X = model.transform(X)\n",
    "# input_shape = (1,)\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "n = 3\n",
    "modelPCA = PCA(n_components=n)\n",
    "#project data on principal components\n",
    "X = modelPCA.fit_transform(X)\n",
    "input_shape = (n,)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.05,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(solver=\"sag\", C=0.1, penalty=\"l2\", tol=1e-20, max_iter=100, random_state=100)\n",
    "lr_model.fit(x_train, y_train)\n",
    "lr_score = lr_model.score(x_test, y_test)\n",
    "lr_pred = lr_model.predict(x_test)\n",
    "print(\"lr_score: \", lr_score)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score = roc_auc_score(y_test,lr_model.predict_proba(x_test)[:, 1])\n",
    "print(\"roc_score: \",roc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_lr = confusion_matrix(y_test,lr_pred)\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.suptitle(\"Confusion Matrixes\",fontsize=24)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "sns.heatmap(cm_lr,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for theory about no of parameters vs data rows\n",
    "# test different activation functions\n",
    "# check classifiers\n",
    "# check general pourpose layers instead of dense ones\n",
    "# check loss function\n",
    "# check optimizer for loss function\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Flatten(input_shape=(10,)))\n",
    "#model.add(Dense(10, activation=tf.nn.relu))\n",
    "#model.add(Dense(5, activation=tf.nn.relu))\n",
    "model.add(Dense(256, activation=tf.nn.relu, input_shape=input_shape))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "#non-working attempt at a custom loss function as in: https://towardsdatascience.com/explicit-auc-maximization-70beef6db14e\n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     # calculate loss, using y_pred\n",
    "#     alpha = tf.sigmoid(y_pred @ tf.transpose(y_pred))\n",
    "#     beta = np.maximum(y_true @ np.ones(y_true.shape).T - np.ones(y_true.shape) @ y_true.T)\n",
    "#     loss = - tf.reduce_mean(alpha * beta, 0)\n",
    "#     return loss\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dnn_history.history['accuracy'])\n",
    "plt.plot(dnn_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0, 1)\n",
    "plt.legend(['Training data', 'Validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dnn_history.history['loss'])\n",
    "plt.plot(dnn_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(0, 1)\n",
    "plt.legend(['Training data', 'Validation data'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_score = model.evaluate(x_test, y_test)\n",
    "dnn_pred = model.predict(x_test)\n",
    "\n",
    "# input_test = np.array([\n",
    "#     [2,4,3,0.1,0.17,-10,102,-1,3,244],\n",
    "#     [0.1,0.2,0.3,0.4,0.2412,1,0.5,-20,1,2]])\n",
    "# input_pred = model.predict(input_test)\n",
    "# print(\"input_pred: \",input_pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score = roc_auc_score(y_test,dnn_pred)\n",
    "print(\"roc score: \", roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
